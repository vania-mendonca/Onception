{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onception\n",
    "\n",
    "Online learning x (Active Learning x (Online learning x Machine Translation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path # only supported in Python 3\n",
    "import os\n",
    "import re\n",
    "\n",
    "from io_utils import *\n",
    "from nlp_utils import *\n",
    "from OnlineAlgorithm import *\n",
    "from QueryStrategy import *\n",
    "from TaskModel import *\n",
    "from Instance import *\n",
    "from qs_params import *\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "Online learning x Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EWAF / EXP3 params\n",
    "algorithm_mt = \"EXP3\" #\"EXP3\" # \"EWAF\n",
    "eta_param_mt = 8 # weight update (EWAF)\n",
    "dp_mt = 2 # reward decimal places\n",
    "reward_function_mt = \"human\"\n",
    "#\"human\" \"human-avg\" \"human-comet\" \"comet\" \"bleu\"\n",
    "\n",
    "# MT params\n",
    "src_lang = \"lt\"\n",
    "mt_lang = \"en\"\n",
    "\n",
    "lang = src_lang + \"-\" + mt_lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online learning x Active Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EWAF / EXP3 params\n",
    "algorithm_al = \"EWAF\"\n",
    "eta_param_al = 8 # weight update (EWAF)\n",
    "dp_al = 2 # reward decimal places\n",
    "reward_function_al = \"regret\"\n",
    "\n",
    "# AL\n",
    "\n",
    "#All #NoDen #NoPrism\n",
    "query_strategies_exp = query_strategies_params[lang][algorithm_mt][\"All\"]\n",
    "\n",
    "query_strategies_exp_str = []\n",
    "for qs in query_strategies_exp:\n",
    "    qs_name, qs_params = qs\n",
    "    qs_params2 = re.sub(\"\\'|\\(|\\)|,| \", \"\", str(qs_params))\n",
    "    query_strategies_exp_str.append(qs_name + qs_params2)\n",
    "    \n",
    "query_strategies_str = \"+\".join(query_strategies_exp_str)\n",
    "print(query_strategies_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run =\"1\"\n",
    "\n",
    "data_folder = Path(\"datasets/{}/\".format(lang))\n",
    "emb_folder = Path(\"embeddings/\")\n",
    "results_folder = Path(\"results/{}/\".format(lang))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_settings = \"{}_{}_{}_{}_{}_{}_{}_{}_run{}\".format(algorithm_al, dp_al, eta_param_al, query_strategies_str, algorithm_mt, reward_function_mt, dp_mt, eta_param_mt, run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_sent_ids_filepath = data_folder / \"shuf_ids.txt\"\n",
    "corpus_filepath = data_folder / \"{}_prism.pickle\".format(lang)\n",
    "\n",
    "learning_ids = load_int_list_from_txt(learn_sent_ids_filepath)\n",
    "print(\"First:\", learning_ids[0])\n",
    "\n",
    "full_corpus = load_dataframe_from_pickle(corpus_filepath)\n",
    "\n",
    "print(full_corpus.iloc[0])\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_emb_filepath = emb_folder / \"BERT_{}_src_{}.pickle\".format(lang, src_lang)\n",
    "mt_emb_filepath = emb_folder / \"BERT_{}_mt_{}.pickle\".format(lang, mt_lang)\n",
    "\n",
    "src_embeddings = load_dict_from_pickle(src_emb_filepath)\n",
    "mt_embeddings = load_dict_from_pickle(mt_emb_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lang == \"en-de\":\n",
    "    idx = 'sent_id'\n",
    "else:\n",
    "    idx = 'sid'\n",
    "\n",
    "all_model_names = list(full_corpus.system.unique())\n",
    "all_models = []\n",
    "\n",
    "num_of_models = len(all_model_names)\n",
    "\n",
    "for model_name in all_model_names:\n",
    "    \n",
    "    system_info = full_corpus.loc[full_corpus['system'] == model_name]\n",
    "    \n",
    "    translations = dict(zip(system_info[idx], system_info['mt']))\n",
    "    human_scores = dict(zip(system_info[idx], system_info['raw_score']))\n",
    "    bleu_scores = dict(zip(system_info[idx], system_info['bleu_score']))\n",
    "    comet_scores = dict(zip(system_info[idx], system_info['comet_score']))\n",
    "    \n",
    "    model = TaskModel(model_name, translations, human_scores, bleu_scores, comet_scores, num_of_models, reward_function_mt)\n",
    "    all_models.append(model)\n",
    "    \n",
    "    print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outer online learning init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qs = len(query_strategies_exp)\n",
    "print(num_qs)\n",
    "\n",
    "oa_al = init_online_algorithm(algorithm_al, num_qs, decimal_places=dp_al, eta_value=eta_param_al, reward_function=reward_function_al)\n",
    "print(oa_al)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Active Learning init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_strategies = []\n",
    "\n",
    "for qs in query_strategies_exp:\n",
    "    qs_name, params = qs\n",
    "    new_strategy = init_query_strategy(qs_name, params, num_qs, reward_function_al)    \n",
    "    print(new_strategy)\n",
    "    query_strategies.append(new_strategy)\n",
    "    \n",
    "print(len(query_strategies)) \n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = []\n",
    "U = []\n",
    "\n",
    "for sent_id in learning_ids:\n",
    "    \n",
    "    full_info = full_corpus.loc[full_corpus[idx] == sent_id]\n",
    "    \n",
    "    src_sentence = str(full_info['src'].iloc[0])\n",
    "    src_sentence_pp = remove_punctuation(src_sentence)    \n",
    "    src_embedding = src_embeddings[sent_id]\n",
    "    \n",
    "    inst = Instance(sent_id, src_sentence, src_sentence_pp, src_embedding)\n",
    "    \n",
    "    model_names = list(full_info.system.unique())\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        system_info = full_info.loc[full_corpus['system'] == model_name]\n",
    "        \n",
    "        mt_sentence = str(system_info['mt'].iloc[0])\n",
    "        mt_sentence_pp = remove_punctuation(mt_sentence)\n",
    "        mt_embedding = mt_embeddings[model_name][sent_id]\n",
    "        \n",
    "        mt_prism_score = float(system_info['prism_score'].iloc[0]) \n",
    "        \n",
    "        inst.add_mt(model_name, mt_sentence, mt_sentence_pp, mt_embedding, mt_prism_score)\n",
    "    \n",
    "    U.append(inst)\n",
    "\n",
    "print(len(U))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inner Online Learning init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa_mt = init_online_algorithm(algorithm_mt, num_of_models, decimal_places=dp_mt, eta_value=eta_param_mt, reward_function=reward_function_mt)\n",
    "print(oa_mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_filepath = results_folder / \"weights_{}.csv\".format(exp_settings)\n",
    "\n",
    "# print initial weights\n",
    "models_str = [str(m.model_name) for m in all_models]\n",
    "weights_str = [str(w) for w in oa_mt.weights_as_probabilities]\n",
    "\n",
    "with weights_filepath.open(\"w\", encoding=\"utf8\") as f:\n",
    "    print(','.join(models_str), file=f)\n",
    "    print(','.join(weights_str), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_qs_filepath = results_folder / \"weights_qs_{}.csv\".format(exp_settings)\n",
    "\n",
    "# print initial weights\n",
    "qs_str =  [\"{}-{}\".format(qs.name, str(qs.sm)) for qs in query_strategies]\n",
    "weights_qs_str = [str(w) for w in oa_al.weights_as_probabilities]\n",
    "\n",
    "with weights_qs_filepath.open(\"w\", encoding=\"utf8\") as f:\n",
    "    print(','.join(qs_str), file=f)\n",
    "    print(','.join(weights_qs_str), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regret_mt_filepath = results_folder / \"regret_mt_{}.csv\".format(exp_settings)\n",
    "\n",
    "with regret_mt_filepath.open(\"w\", encoding=\"utf8\") as f:\n",
    "    print(\"Regret OL_MT\", file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regret_al_filepath = results_folder / \"regret_al_{}.csv\".format(exp_settings)\n",
    "\n",
    "with regret_al_filepath.open(\"w\", encoding=\"utf8\") as f:\n",
    "    print(\"Regret OL_AL\", file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = 1\n",
    "\n",
    "U_copy = U.copy()\n",
    "U_log = []\n",
    "\n",
    "for sent_id in learning_ids:\n",
    "    \n",
    "    current_inst = U_copy[t-1]\n",
    "\n",
    "    print(\" ------------------------- ITERATION {} -------------------------\".format(t))  \n",
    "    \n",
    "    f_prediction = oa_mt.forecaster(all_models, params=sent_id)\n",
    "    vote = oa_al.forecaster(query_strategies, params=(current_inst, L, U_log))\n",
    "    \n",
    "    if t == 1 or vote:\n",
    "        \n",
    "        oa_mt.update(all_models, t, params=sent_id)\n",
    "        \n",
    "        L.append(current_inst)\n",
    "        U.remove(current_inst)\n",
    "        \n",
    "        oa_al.update(query_strategies, t, params=(oa_mt.previous_regret, oa_mt.regret, algorithm_mt))\n",
    "\n",
    "        ### print weights MT\n",
    "        weights_str = [str(w) for w in oa_mt.weights_as_probabilities]    \n",
    "        with weights_filepath.open(\"a\", encoding=\"utf8\") as f:\n",
    "            print(','.join(weights_str), file=f)\n",
    "        \n",
    "        ### print weights AL\n",
    "        weights_qs_str = [str(w) for w in oa_al.weights_as_probabilities]\n",
    "        with weights_qs_filepath.open(\"a\", encoding=\"utf8\") as f:\n",
    "            print(','.join(weights_qs_str), file=f)\n",
    "\n",
    "        ### print regret MT\n",
    "        with regret_mt_filepath.open(\"a\", encoding=\"utf8\") as f:\n",
    "            print(oa_mt.regret, file=f)\n",
    "            \n",
    "        ### print regret AL\n",
    "        with regret_al_filepath.open(\"a\", encoding=\"utf8\") as f:\n",
    "            print(oa_al.regret, file=f)\n",
    "    else:\n",
    "        U_log.append(current_inst)\n",
    "            \n",
    "\n",
    "    t = t + 1\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ewaal",
   "language": "python",
   "name": "ewaal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
